{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb023fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import PIL\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import style\n",
    "\n",
    "\n",
    "DATA = 'ARTS'\n",
    "# DATA = \"GTSRB\"\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "PATH_TO_IMAGE = \"<PATH_TO_IMAGE_FILE>\"\n",
    "\n",
    "image_size = 60\n",
    "IMG_HEIGHT = 60\n",
    "IMG_WIDTH = 60\n",
    "\n",
    "NUM_CATEGORIES = 43\n",
    "\n",
    "class GtsrbDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.paths = df['path'].values\n",
    "        self.labels = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(PIL.Image.open(self.paths[index]).convert('RGB'))\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=img)\n",
    "            img = res['image']\n",
    "\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    albumentations.Normalize()\n",
    "])\n",
    "\n",
    "#valid_dataset = GtsrbDataset(df_train, 'valid', transform=transforms_valid)\n",
    "\n",
    "map_models = {}\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(18432, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# load classifier\n",
    "model = SimpleCNN(NUM_CATEGORIES)\n",
    "kernel_type = 'SimpleCNN'\n",
    "\n",
    "data = torch.load(f'models_60/SimpleCNN_{DATA}_best_loss.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(data['model'])\n",
    "    \n",
    "classes_GTSRB = data['classes']\n",
    "model = model.to(device).eval()\n",
    "map_models['SimpleCNN'] = model, classes_GTSRB\n",
    "# STOPSIGN = 14 # GTSRB\n",
    "\n",
    "STOPSIGN = 12 # ARTS\n",
    "from datetime import datetime\n",
    "\n",
    "class GtsrbDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.paths = df['path'].values\n",
    "        self.labels = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(PIL.Image.open(self.paths[index]).convert('RGB'))\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=img)\n",
    "            img = res['image']\n",
    "\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    albumentations.Normalize()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9030174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4.285] global loadsave.cpp:268 findDecoder imread_('crp2.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n\u001b[0;32m----> 4\u001b[0m at_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m transforms_valid(image\u001b[38;5;241m=\u001b[39mat_image)\n\u001b[1;32m      7\u001b[0m img \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "path = PATH_TO_IMAGE\n",
    "import cv2\n",
    "image = cv2.imread(path)\n",
    "at_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "res = transforms_valid(image=at_image)\n",
    "img = res['image']\n",
    "img = torch.tensor(img.transpose(2, 0, 1))#.unsqueeze(0)\n",
    "img = torch.stack([img], axis=0).to(device)\n",
    "map_res = {}\n",
    "\n",
    "# text = '/'.join(PATH_TO_IMAGE.split('/')[-2:])\n",
    "text = '/'.join(path.split('/')[-2:])\n",
    "name_ = str(text)\n",
    "\n",
    "all_res = []\n",
    "for k, (model, classes_GTSRB) in map_models.items():\n",
    "    pred = model(img).softmax(axis=1).cpu().detach().numpy()\n",
    "    label = pred.argmax(axis=1)[0]\n",
    "\n",
    "    text += f'\\n{DATA} {k}: {classes_GTSRB[label]} ({pred.max():.2f})' # model_name,class,(prob)\n",
    "    prob_of_stopsign = pred[0][STOPSIGN]\n",
    "    prob = pred.max()\n",
    "    map_res = dict(name=name_, label=classes_GTSRB[label], prob=pred.max(), model=k)\n",
    "\n",
    "    all_res.append(map_res)\n",
    "\n",
    "print(text) \n",
    "print(prob_of_stopsign)\n",
    "plt.imshow(at_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
